{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from pyhht.visualization import plot_imfs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook, export\n",
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import LinearColorMapper, BasicTicker, ColorBar\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models.glyphs import Step\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils_cython.data_utils_c import derivative\n",
    "from utils.data_utils import (csvs_merge, cumsum, step_change_point, rms, imfs_decomposition,\n",
    "                              hankel_svd, correlation_coeffs, cross_correlation, \n",
    "                              fft_spectrogram, poly_coeffs, scatter3d_plot, Bearing)\n",
    "\n",
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create folders for processed data and merge all .csv files of each bearing in FEMTO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'data/processed_data/femto_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4f0432e7473d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'femto_dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/processed_data/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbearing\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/original_data/%s/'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'data/processed_data/femto_dataset'"
     ]
    }
   ],
   "source": [
    "files_info = {\n",
    "    # file type identifier, columns name, columns to read.\n",
    "    'acc'  : {'usecols' : [0, 1, 2, 4, 5], 'names' : ['hour', 'min', 'seg', 'h_acc', 'v_acc']},\n",
    "    'temp' : {'usecols' : [0, 1, 2, 4],    'names' : ['hour', 'min', 'seg', 'temp']}\n",
    "}\n",
    "\n",
    "dataset = 'femto_dataset'\n",
    "os.mkdir('data/processed_data/%s' % (dataset))\n",
    "\n",
    "for bearing in os.listdir('data/original_data/%s/' % (dataset)):\n",
    "    # Creating folders for processed data.\n",
    "    os.mkdir('data/processed_data/%s/%s' % (dataset, bearing))\n",
    "    \n",
    "    # Merging .csv files.\n",
    "    csvs_merge('data/original_data/%s/%s' % (dataset, bearing), files_info, bearing, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read merged files and create bearings objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearings_to_read = ['Bearing1_1', 'Bearing1_2', 'Bearing1_3', 'Bearing1_4', 'Bearing1_5', \n",
    "                    'Bearing1_6', 'Bearing1_7', 'Bearing2_1', 'Bearing2_2', 'Bearing2_3', \n",
    "                    'Bearing2_4', 'Bearing2_5', 'Bearing2_6', 'Bearing2_7', 'Bearing3_1', \n",
    "                    'Bearing3_2', 'Bearing3_3']\n",
    "\n",
    "dataset = 'femto_dataset'\n",
    "bearings = []\n",
    "for bearing_to_read in bearings_to_read:\n",
    "    data = {'vib' : pd.read_csv('data/processed_data/%s/%s/acc_merged.csv' % (dataset, bearing_to_read))}\n",
    "    \n",
    "    # Reads 'temperature' if the data exists.\n",
    "    if os.path.exists('data/processed_data/%s/temp_merged.csv' % (bearing_to_read)):\n",
    "            data['temp'] = pd.read_csv('data/processed_data/%s/%s/temp_merged.csv' % (dataset, bearing_to_read))\n",
    "    \n",
    "    bearings.append(Bearing(name=bearing_to_read, dataset=dataset, condition=bearing_to_read[7],\n",
    "                            data=data, restore_results=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT Spectogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT Analysis\n",
    "window_size = 2560; fs=25600\n",
    "for bearing in bearings:\n",
    "\n",
    "    bearing.results['fft_spectrogram'] = {'h' :  fft_spectrogram(bearing.data['vib']['h_acc'], \n",
    "                                                                 window_size=window_size, fs=fs), \n",
    "                                          \n",
    "                                          'v' :  fft_spectrogram(bearing.data['vib']['v_acc'],\n",
    "                                                                 window_size=window_size, fs=fs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3D Spectogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " step = 6; x, y, z = bearings[0].results['fft_spectrogram']['v']\n",
    "scatter3d_plot(filename='fft_spectrogram_3d.html', x=np.hstack(x)[::step], y=np.hstack(y)[::step], z=np.hstack(z)[::step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2D FFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = bearings[0].results['fft_spectrogram']['v']\n",
    "x, y, z = x[::20], y[::20], z[::20] \n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharey=True, gridspec_kw={'hspace': 1})\n",
    "ax1.bar(x[0], z[0], width=1.5)\n",
    "ax1.set_xlabel('Frequency (Hz)')\n",
    "ax1.set_ylabel('Magnitude')\n",
    "ax1.set_title('Beginning')\n",
    "\n",
    "ax2.bar(x[len(x)//2], z[len(x)//2], width=1.5)\n",
    "ax2.set_xlabel('Frequency (Hz)')\n",
    "ax2.set_ylabel('Magnitude')\n",
    "ax2.set_title('Middle')\n",
    "\n",
    "ax3.bar(x[len(x)-50], z[len(x)-50], width=1.5)\n",
    "ax3.set_xlabel('Frequency (Hz)')\n",
    "ax3.set_ylabel('Magnitude')\n",
    "ax3.set_title('Almost End')\n",
    "\n",
    "ax4.bar(x[-1], z[-1], width=1.5)\n",
    "ax4.set_xlabel('Frequency (Hz)')\n",
    "ax4.set_ylabel('Magnitude')\n",
    "ax4.set_title('End')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hilbert Huang Transform Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMFs Decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilbert Huang Transform Analysis\n",
    "hht_window_size = 2*2560\n",
    "for bearing in bearings:\n",
    "\n",
    "    bearing.results['imfs'] = {'h' : imfs_decomposition(bearing.data['vib']['h_acc'], window_size=hht_window_size), \n",
    "                               'v' : imfs_decomposition(bearing.data['vib']['v_acc'], window_size=hht_window_size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bearings[0].results['imfs']['v']\n",
    "\n",
    "imf = 5\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharey=True, gridspec_kw={'hspace': 1})\n",
    "ax1.plot(data[0][imf])\n",
    "ax1.set_ylabel('Magnitude')\n",
    "ax1.set_title('IMF 0')\n",
    "\n",
    "ax2.plot(data[len(data)//2][imf])\n",
    "ax2.set_ylabel('Magnitude')\n",
    "ax2.set_title('IMF 0')\n",
    "\n",
    "ax3.plot(data[len(data)-100][imf])\n",
    "ax3.set_ylabel('Magnitude')\n",
    "ax3.set_title('IMF 0')\n",
    "\n",
    "ax4.plot(data[len(data)-1][imf])\n",
    "ax4.set_ylabel('Magnitude')\n",
    "ax4.set_title('IMF 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting IMFs and saving plots.\n",
    "s_imfs = []\n",
    "colors = itertools.cycle(palette)\n",
    "for (i, bearing), color in zip(enumerate(bearings), colors):\n",
    "    data = bearing.results['imfs']['v']\n",
    "    n_imfs = min([len(x) for x in data])\n",
    "    times = [0, len(data)//2, len(data)-100, len(data)-1]\n",
    "    times_text = ['Beginning', 'Middle', 'Almost End', 'End']\n",
    "    for imf in range(n_imfs):\n",
    "        s_imf = []\n",
    "        for i, t in enumerate(times):\n",
    "            s = figure(plot_width = 500, plot_height = 500, \n",
    "                      title = 'IMF %s. %s.' % (imf, times_text[i]),\n",
    "                      x_axis_label = 'Recordings', y_axis_label = 'Magnitude')\n",
    "\n",
    "            x = np.arange(len(data[t][imf])); y = data[t][imf] \n",
    "            s.line(x=x, y=y, color=color, legend_label=\"%s\" %(bearing.name))\n",
    "\n",
    "            s.legend.location = \"top_left\"\n",
    "\n",
    "            s_imf.append(s)\n",
    "        s_imfs.append(s_imf)\n",
    "\n",
    "for t_imfs in s_imfs:\n",
    "    y_first_range = t_imfs[0].y_range\n",
    "    for t_imf in t_imfs:\n",
    "        t_imf.y_range = y_first_range\n",
    "    \n",
    "        \n",
    "imfs_plot = []\n",
    "for i in range(4):\n",
    "    imfs_plot.append([imf[i] for imf in s_imfs])\n",
    "\n",
    "show(( row(column(imfs_plot[0]), column(imfs_plot[1]), column(imfs_plot[2]), column(imfs_plot[3])) ))\n",
    "export.export_png(row(column(imfs_plot[0]), column(imfs_plot[1]), column(imfs_plot[2]), column(imfs_plot[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumsum and Derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumsum and derivative analysis.\n",
    "for bearing in bearings:\n",
    "    # Computing cumsum.\n",
    "    bearing.results['cumsum'] = {'h' : cumsum(bearing.data['vib']['h_acc']), \n",
    "                                 'v' : cumsum(bearing.data['vib']['v_acc'])}\n",
    "    \n",
    "    \"\"\"# Computing cumsum derivative.\n",
    "    h = 39*10**-6 # Distance between points - It's in original data in u-sec column.\n",
    "    bearing.results['cs_derivative'] = {'h' : np.asarray(derivative(bearing.results['cumsum']['h'].values, h)), \n",
    "                                        'v' : np.asarray(derivative(bearing.results['cumsum']['v'].values, h))}\n",
    "    \n",
    "    # Marking change points (cp) in derivative.\n",
    "    bearing.results['cs_deriv_cp'] = {'h' : step_change_point(bearing.results['cs_derivative']['h']),\n",
    "                                      'v' : step_change_point(bearing.results['cs_derivative']['v'])}\"\"\"\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 71756), ('y', 71757)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 71756), ('y', 71757)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 22297), ('y', 22298)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 22297), ('y', 22298)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 36556), ('y', 36557)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 36556), ('y', 36557)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 63052), ('y', 63053)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 63052), ('y', 63053)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 62668), ('y', 62669)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 62668), ('y', 62669)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 57830), ('y', 57831)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 57830), ('y', 57831)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 23321), ('y', 23322)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 23321), ('y', 23322)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 20403), ('y', 20404)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 20403), ('y', 20404)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 19225), ('y', 19226)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 19225), ('y', 19226)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 59161), ('y', 59162)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 59161), ('y', 59162)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 17945), ('y', 17946)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 17945), ('y', 17946)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 41907), ('y', 41908)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 41907), ('y', 41908)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 11110), ('y', 11111)\n",
      "\n",
      "/home/az/.local/lib/python3.7/site-packages/bokeh/models/sources.py:173: BokehUserWarning:\n",
      "\n",
      "ColumnDataSource's columns must be of the same length. Current lengths: ('x', 11110), ('y', 11111)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plotting cumsum and saving plots.\n",
    "s_cs = []\n",
    "colors = itertools.cycle(palette)\n",
    "for i, bearing in enumerate(bearings):\n",
    "    \n",
    "    s = figure(plot_width = 500, plot_height = 500, \n",
    "                  title = 'Cumulative Sum.',\n",
    "                  x_axis_label = 'Recordings', y_axis_label = 'Cumulative Sum')\n",
    "    \n",
    "    for (label_l, data), color in zip(bearing.results['cumsum'].items(), colors):\n",
    "        # Get data points spaced by sample_step. \n",
    "        x = np.arange(len(data)//100); data = data[::100]\n",
    "        # Add circle glyph.\n",
    "        s.circle(x=x, y=data, color=color, size=1, legend_label=\"%s, %s\" %(bearing.name, label_l))\n",
    "    \n",
    "    s.legend.location = \"top_left\"\n",
    "    \n",
    "    s_cs.append(s)\n",
    "    \n",
    "show(column(s_cs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with fft spectrum analysis.\n",
    "for bearing in bearings:\n",
    "    # Computing fft spectogram.\n",
    "    bearing.results['rms'] = {'h' : rms(bearing.data['vib']['h_acc'].values, window_size=2560), \n",
    "                              'v' : rms(bearing.data['vib']['v_acc'].values, window_size=2560)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting cumsum and saving plots.\n",
    "s_rms = []\n",
    "colors = itertools.cycle(palette)\n",
    "for i, bearing in enumerate(bearings):\n",
    "    \n",
    "    s = figure(plot_width = 500, plot_height = 500, \n",
    "                  title = 'RMS.',\n",
    "                  x_axis_label = 'Recordings', y_axis_label = 'RMS')\n",
    "    \n",
    "    for (label_l, data), color in zip(bearing.results['rms'].items(), colors):\n",
    "        # Get data points spaced by sample_step. \n",
    "        x = np.arange(len(data));\n",
    "        # Add circle glyph.\n",
    "        s.circle(x=x, y=data, color=color, size=1, legend_label=\"%s, %s\" %(bearing.name, label_l))\n",
    "    \n",
    "    s.legend.location = \"top_left\"\n",
    "    \n",
    "    s_rms.append(s)\n",
    "    \n",
    "show(row(column(s_rms), column(s_cs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mao et. al. - Correlation coefficient.\n",
    "<sub>Mao, W., He, J., Tang, J. and Li, Y., 2018. Predicting remaining useful life of rolling bearings based on deep feature representation and long short-term memory neural network. Advances in Mechanical Engineering, 10(12), p.1687814018817184."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bearing in bearings:\n",
    "    # Compute hankel matrix singular values.\n",
    "    bearing.results['hankel_svd'] = {'h' : hankel_svd(bearing.data['vib']['h_acc'], hankel_window_size=9,\n",
    "                                                      slice_window_size=len(bearing.data['vib']['h_acc'])//2560),\n",
    "                                     \n",
    "                                     'v' : hankel_svd(bearing.data['vib']['v_acc'], hankel_window_size=9, \n",
    "                                                      slice_window_size=len(bearing.data['vib']['v_acc'])//2560)}\n",
    "    \n",
    "    # Compute correlation coefficients.\n",
    "    bearing.results['hankel_svd_correlation_coeffs'] = {'h' : correlation_coeffs(bearing.results['hankel_svd']['h'], \n",
    "                                                        baseline_percentage=20, norm_interval=[-1, 1]),\n",
    "                                                  \n",
    "                                                        'v' : correlation_coeffs(bearing.results['hankel_svd']['v'],\n",
    "                                                        baseline_percentage=20, norm_interval=[-1, 1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Hankel matrix singular values correlation coefficients.\n",
    "s_h_svd = []\n",
    "colors = itertools.cycle(palette)\n",
    "for bearing in bearings:\n",
    "    s = figure(plot_width = 500, plot_height = 500, \n",
    "           title = 'Hankel matrix singular values correlation coefficients.',\n",
    "           x_axis_label = 'Recordings', y_axis_label = 'Correlation coefficients')\n",
    "    \n",
    "    for (label_l, data), color in zip(bearing.results['hankel_svd_correlation_coeffs'].items(), colors):\n",
    "        x = np.arange(len(data))\n",
    "        # Add circle glyph.\n",
    "        s.circle(x=x, y=data, color=color, legend_label='%s, %s' % (bearing.name, label_l))\n",
    "    \n",
    "    s.legend.location = 'bottom_left'\n",
    "    \n",
    "    s_h_svd.append(s)\n",
    "\n",
    "show(row(column(s_h_svd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "<sub> https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "for bearing in bearings:\n",
    "    # Adjusting shape and zero mean.\n",
    "    h = np.squeeze(StandardScaler(with_mean=True, with_std=True).fit_transform(bearing.results['cumsum']['h'].values.reshape(-1 ,1)))\n",
    "    v = np.squeeze(StandardScaler(with_mean=True, with_std=True).fit_transform(bearing.results['cumsum']['v'].values.reshape(-1 ,1)))\n",
    "    \n",
    "    # Adding np.arange column and compute PCA.\n",
    "    bearing.results['cs_pca'] = {'h' : pca.fit_transform(list(zip(np.arange(len(h)), h))), \n",
    "                                 'v' : pca.fit_transform(list(zip(np.arange(len(v)), v)))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting pca components.\n",
    "s_pca = []\n",
    "colors = itertools.cycle(palette)\n",
    "for bearing in bearings:\n",
    "    \n",
    "    s = figure(plot_width = 500, plot_height = 500, \n",
    "           title = 'PCA Components.',\n",
    "           x_axis_label = 'Component 1', y_axis_label = 'Component 2')\n",
    "    \n",
    "    for (label_l, data), color in zip(bearing.results['cs_pca'].items(), colors):\n",
    "        # Get each data point after sample_step. \n",
    "        data = data[::2560]\n",
    "        # Add circle glyph.\n",
    "        s.circle(x=data[:, 0], y=data[:, 1], color=color, legend_label=\"%s, %s\" %(bearing.name, label_l))\n",
    "\n",
    "    s.legend.location = \"top_left\"\n",
    "    \n",
    "    s_pca.append(s)\n",
    "    \n",
    "show(row(column(s_pca), column(s_cs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting all results.  \n",
    "show((row(column(s_cs), column(s_deriv), column(s_h_svd), column(s_pca))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpd38nyegp.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving results to binary.\n",
    "for bearing in bearings:\n",
    "    bearing.save_r()\n",
    "\n",
    "# Exporting all results to image.\n",
    "# https://docs.bokeh.org/en/latest/docs/user_guide/export.html?highlight=export\n",
    "export.export_png(row(column(s_cs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUL Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bearing_rul_predict",
   "language": "python",
   "name": "bearing_rul_predict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "273.969px",
    "width": "392.188px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "709.091px",
    "left": "132px",
    "top": "151.418px",
    "width": "657.443px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
